[LLM]
llm_model = ./model_assets/LocalLLM/swallow-13b-instruct.Q4_K_M.gguf
n_gpu_layers_num = -1
n_ctx = 2048
max_tokens = 1024
temperature = 1.0
cpu_mode = True
verbose = False
